
# âœ¨ Ghibli Style Transfer using CycleGAN ğŸ¨
[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://cyclegan-app-6cvc3wgympvy9tskshngmf.streamlit.app/)

> ğŸ§  Transform real-world images into Studio Ghibli-style illustrations using a CycleGAN model built from scratch in PyTorch.  
> ğŸš€ Developed as a deep learning project by the **Fusion Eyes** team.

---

## ğŸ“Œ Table of Contents

- [ğŸ“– Overview](#-overview)
- [ğŸ¯ Objectives](#-objectives)
- [ğŸ§  Motivation](#-motivation)
- [ğŸ“ Dataset](#-dataset)
- [ğŸ›  Preprocessing](#-preprocessing)
- [ğŸ§° Model Architecture](#-model-architecture)
- [ğŸ§ª How to Run](#-how-to-run)
- [ğŸ“¦ Requirements](#-requirements)
- [ğŸ“¸ Results](#-results)
- [ğŸ“Š Challenges & Discussion](#-challenges--discussion)
- [ğŸ”® Future Work](#-future-work)
- [ğŸ“„ Resources & Report](#-resources--report)
- [ğŸ“¬ Contact](#-contact)

---

## ğŸ“– Overview

Studio Ghibli animations are renowned for their warm color tones, fantasy landscapes, and emotional depth. This project leverages CycleGAN to bring that hand-drawn magic to real-world images â€” all without paired data or pre-trained models.

**Project Title:** *Ghibli Style Transfer using CycleGAN*  
**Team Name:** *Fusion Eyes*  
**Team Members:**
- ğŸ‘¤ Kanan Pandit (B2430051)
- ğŸ‘¤ Partha Mete (B2430052)

---

## ğŸ¯ Objectives

- ğŸ§¾ Transform real-world photographs into Studio Ghibli-style images.
- â™»ï¸ Use **CycleGAN** for unpaired image-to-image translation.
- ğŸ§± Preserve semantic structures (e.g., faces, scenes).
- ğŸ’» Implement the model **from scratch** for deeper understanding.

---

## ğŸ§  Motivation

> Why Ghibli?

Studio Ghibli films evoke nostalgia, warmth, and fantasy. Their distinct visual style is challenging for AI to replicate â€” making them perfect for testing the limits of deep learning in aesthetic transformation.

---

## ğŸ“ Dataset

ğŸ“‚ **Dataset Name**: [Real to Ghibli Image Dataset (Kaggle)](https://www.kaggle.com/datasets/shubham1921/real-to-ghibli-image-dataset-5k-paired-images)  
ğŸ–¼ï¸ **Images**: 5,000  
ğŸ§¾ **Unpaired** â€” no 1:1 correspondence

### ğŸ” `trainA` â€“ Real Domain:
- Human portraits, nature, cities, rivers, forests

### ğŸ¨ `trainB` â€“ Ghibli Domain:
- Fantasy villages, hand-drawn characters, magic landscapes

---

## ğŸ›  Preprocessing

| Step               | Purpose                          |
|--------------------|----------------------------------|
| Resize to 286Ã—286  | Uniform dimensions               |
| Random crop 256Ã—256| Introduce variation              |
| Horizontal flip    | Data augmentation                |
| Normalize to [-1, 1]| GAN-friendly input scaling       |

---

## ğŸ§° Model Architecture

### ğŸŒ€ CycleGAN Structure

| Component | Role                                 |
|-----------|---------------------------------------|
| `G_AB`    | Generator: Real â†’ Ghibli              |
| `G_BA`    | Generator: Ghibli â†’ Real              |
| `D_A`     | Discriminator: Real domain            |
| `D_B`     | Discriminator: Ghibli domain          |

### ğŸ§  Generator (ResNet-based)
- Reflection padding  
- 6 Ã— Residual Blocks  
- InstanceNorm, ReLU, Tanh

### ğŸ›¡ï¸ Discriminator (PatchGAN)
- Operates on 70Ã—70 patches  
- Preserves local texture details

### ğŸ“¦ Loss Functions
- **Adversarial Loss (MSELoss)**  
- **Cycle Consistency Loss (L1)**  
- **Identity Loss (L1)**

---

## ğŸ§ª How to Run

### âœ… Google Colab (Recommended)

1. Open the notebook: [`FiNAL_CV_GHIBHLI_STYLE_TRANSFER.ipynb`](FiNAL_CV_GHIBHLI_STYLE_TRANSFER.ipynb)  
2. Set runtime to **GPU**  
3. Upload the dataset and run all cells

---

### ğŸ–¥ï¸ Local Setup (Optional)

```bash
git clone https://github.com/kananpandit02/ghibli-style-transfer.git
cd ghibli-style-transfer
pip install -r requirements.txt
python train.py --dataset_dir ./dataset --epochs 50 --batch_size 1
```

---

## ğŸ“¦ Requirements

```
torch
torchvision
numpy
Pillow
matplotlib
tqdm
```

---

## ğŸ“¸ Results

> Real â†’ Ghibli style image transformation

- Identity preserved using identity loss
- Texture and style successfully transferred
- Results improve as training progresses

| Input (Real) | Ghibli Output | Reconstructed |
|--------------|---------------|----------------|
| ![](samples/input.jpg) | ![](samples/output.jpg) | ![](samples/recon.jpg) |

---

## ğŸ“Š Challenges & Discussion

| Challenge | Notes |
|----------|-------|
| âš ï¸ GAN Instability | Oscillating losses and mode collapse observed occasionally |
| ğŸŒ Slow Convergence | Used batch size = 1 (as recommended for CycleGAN) |
| âš™ï¸ Hyperparameter tuning | Required manual tuning for loss balance and stability |

Despite these challenges, the model achieved high-quality artistic translation.

---

## ğŸ”® Future Work

- ğŸ§  Add attention mechanisms (UGATIT, Self-Attention)  
- ğŸ¨ Introduce perceptual loss (VGG-based)  
- ğŸ–¼ï¸ Train with higher-resolution images  
- ğŸŒ Extend or enhance the existing [Streamlit app](https://cyclegan-app-6cvc3wgympvy9tskshngmf.streamlit.app/) for more interactivity or batch processing

---

## ğŸ“„ Resources & Report

- ğŸ“˜ Report: [`CV_PROJECT_FINAL_REPORT_FUSION_EYES_.pdf`](CV_PROJECT_FINAL_REPORT_FUSION_EYES_.pdf)
- ğŸ““ Notebook: `FiNAL_CV_GHIBHLI_STYLE_TRANSFER.ipynb`
- ğŸ“š [CycleGAN Paper](https://arxiv.org/abs/1703.10593)
- ğŸ”— [Official CycleGAN GitHub](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)

---

## ğŸ“¬ Contact

- ğŸ“§ kananpandot02@gmail.com
- ğŸ§‘â€ğŸ’» GitHub: [kananpandit02](https://github.com/kananpandit02/)

---

## ğŸ“¢ Citation

```
@misc{fusioneyes2025ghibli,
  author = {Kanan Pandit and Partha Mete},
  title = {Ghibli Style Transfer using CycleGAN},
  year = {2025},
  url = {https://github.com/kananpandit02/ghibli_style}
}
```

â­ï¸ If you found this helpful, donâ€™t forget to **star** the repository!
