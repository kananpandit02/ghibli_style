# âœ¨ Ghibli Style Transfer using CycleGAN ğŸ¨
[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://cyclegan-app-6cvc3wgympvy9tskshngmf.streamlit.app/)



> ğŸ§  Transform real-world images into Studio Ghibli-style illustrations using a CycleGAN model built from scratch in PyTorch.  
> ğŸš€ Developed as a deep learning project by the **Fusion Eyes** team.

---

## ğŸ“Œ Table of Contents

- [ğŸ“– Overview](#-overview)
- [ğŸ¯ Objectives](#-objectives)
- [ğŸ§  Motivation](#-motivation)
- [ğŸ“ Dataset](#-dataset)
- [ğŸ›  Preprocessing](#-preprocessing)
- [ğŸ§° Model Architecture](#-model-architecture)
- [ğŸ§ª How to Run](#-how-to-run)
- [ğŸ“¦ Requirements](#-requirements)
- [ğŸ“¸ Results](#-results)
- [ğŸ“Š Challenges & Discussion](#-challenges--discussion)
- [ğŸ”® Future Work](#-future-work)
- [ğŸ“„ Resources & Report](#-resources--report)
- [ğŸ“¬ Contact](#-contact)

---

## ğŸ“– Overview

Studio Ghibli animations are renowned for their warm color tones, fantasy landscapes, and emotional depth. This project leverages CycleGAN to bring that hand-drawn magic to real-world images â€” all without paired data or pre-trained models.

**Project Title:** *Ghibli Style Transfer using CycleGAN*  
**Team Name:** *Fusion Eyes*  
**Team Members:**
- ğŸ‘¤ Kanan Pandit (B2430051)
- ğŸ‘¤ Partha Mete (B2430052)

---

## ğŸ¯ Objectives

- ğŸ§¾ Transform real-world photographs into Studio Ghibli-style images.
- â™»ï¸ Use **CycleGAN** for unpaired image-to-image translation.
- ğŸ§± Preserve semantic structures (e.g., faces, scenes).
- ğŸ’» Implement the model **from scratch** for deeper understanding.

---

## ğŸ§  Motivation

> Why Ghibli?

Studio Ghibli films evoke nostalgia, warmth, and fantasy. Their distinct visual style is challenging for AI to replicate â€” making them perfect for testing the limits of deep learning in aesthetic transformation.

---

## ğŸ“ Dataset

ğŸ“‚ **Dataset Name**: [Real to Ghibli Image Dataset (Kaggle)](https://www.kaggle.com/datasets/shubham1921/real-to-ghibli-image-dataset-5k-paired-images)  
ğŸ–¼ï¸ **Images**: 5,000  
ğŸ§¾ **Unpaired** â€” no 1:1 correspondence

### ğŸ” `trainA` â€“ Real Domain:
- Human portraits, nature, cities, rivers, forests

### ğŸ¨ `trainB` â€“ Ghibli Domain:
- Fantasy villages, hand-drawn characters, magic landscapes

---

## ğŸ›  Preprocessing

All images are transformed as follows:

| Step              | Purpose                                    |
|-------------------|--------------------------------------------|
| Resize to 286Ã—286 | Uniform dimensions                         |
| Random crop 256Ã—256 | Variation in training patches            |
| Horizontal flip   | Augmentation                               |
| Normalize to [-1, 1] | GAN-friendly input scaling              |

Implemented using a custom `Dataset` class in PyTorch.

---

## ğŸ§° Model Architecture

### ğŸŒ€ CycleGAN Structure

| Component  | Role                                  |
|------------|----------------------------------------|
| `G_AB`     | Converts Real â†’ Ghibli-style image     |
| `G_BA`     | Converts Ghibli â†’ Real-world image     |
| `D_A`      | Discriminator for real-world images    |
| `D_B`      | Discriminator for Ghibli-style images  |

### ğŸ§  Generator (ResNet-based)

- Reflection padding
- 6 Ã— Residual Blocks
- InstanceNorm, ReLU, Tanh

### ğŸ›¡ï¸ Discriminator (PatchGAN)

- Focuses on `70x70` patches
- Preserves texture and style details

### ğŸ“¦ Loss Functions

- **Adversarial Loss (MSELoss)**  
- **Cycle Consistency Loss (L1 Loss)**  
- **Identity Loss (L1 Loss)**

---

## ğŸ§ª How to Run

### âœ… Google Colab (Recommended)

1. Open: [`FiNAL_CV_GHIBHLI_STYLE_TRANSFER.ipynb`](FiNAL_CV_GHIBHLI_STYLE_TRANSFER.ipynb)
2. Select **GPU Runtime**
3. Upload dataset and run cells

### ğŸ–¥ï¸ Run Locally

```bash
# Clone the repository
git clone https://github.com/yourusername/ghibli-style-transfer.git
cd ghibli-style-transfer

# Install dependencies
pip install -r requirements.txt

# Download dataset manually from Kaggle & place it in:
# ./dataset/trainA and ./dataset/trainB

# Run training
python train.py --dataset_dir ./dataset --epochs 50 --batch_size 1

####ğŸ“Š Challenges & Discussion
Challenge	Notes
âš ï¸ GAN Instability	Oscillating loss values; mode collapse occasionally
ğŸŒ Slow Convergence	Due to batch size = 1 (per CycleGAN recommendation)
âš™ï¸ Hyperparameter tuning	Needed to stabilize training across 50 epochs

Despite challenges, meaningful stylization was achieved.

####ğŸ”® Future Work
ğŸ§  Add attention mechanisms (UGATIT, Self-Attn GAN)

ğŸ¨ Use perceptual loss (VGG-based)

ğŸ–¼ï¸ Train on higher-res datasets

ğŸ’¡ Create a Gradio or Streamlit app for real-time Ghibli-ization


